# imagePullSecrets -- Global image pull secrets
# A list of secrets to use for pulling images from private registries.
# Example:
# imagePullSecrets:
#   - name: "my-registry-secret"
imagePullSecrets: []

# nameOverride -- Override the chart name.
# nameOverride: ""
# fullnameOverride -- Override the full name of the chart.
# fullnameOverride: ""

# tag -- Global fallback image tag for all components.
# Used if a component's specific image.tag is not set.
# If this is also not set (null or empty), Chart.AppVersion is used as the default.
tag: ~

# logLevel -- Global log level for all components. Can be overridden per component.
# Valid levels: "debug", "info", "warn", "error".
logLevel: "info"
# logRemote -- Global setting to enable/disable remote logging for all components. Can be overridden per component.
logRemote: true
# traceRemote -- Global setting to enable/disable remote tracing for all components. Can be overridden per component.
traceRemote: true
# monitorRemote -- Global setting to enable/disable remote monitoring for all components. Can be overridden per component.
monitorRemote: true
# developmentMode -- Global setting for development mode features for all components. Can be overridden per component.
developmentMode: false
# kompassInsightSecret -- Name of the Kubernetes secret created by the Kompass Insight.
kompassInsightSecret: "kompass-insights-secret"

# cache -- Cache component configuration
cache:
  # cache.enabled -- If true, deploys the Cache component.
  enabled: true

  # cache.replicaCount -- Number of replicas for the Cache Deployment.
  replicaCount: 2

  # cache.image -- Image configuration for the Cache component.
  image:
    # cache.image.repository -- Image repository for the Cache component.
    repository: 672188301118.dkr.ecr.eu-west-1.amazonaws.com/zesty-k8s/kompass-compute/cache-controller
    # cache.image.pullPolicy -- Image pull policy. Valid values: Always, IfNotPresent, Never.
    pullPolicy: Always
    # cache.image.tag -- Specific image tag for the Cache component.
    # -- Overrides the global 'tag' and Chart.AppVersion if set.
    # -- If empty, uses global 'tag' or Chart.AppVersion.
    tag: ""

  # cache.extraArgs -- Extra command-line arguments to pass to the Cache container.
  # -- Example:
  # extraArgs:
  #   - --some-flag=value
  extraArgs: [ ]

  # cache.extraEnv -- Extra environment variables to set in the Cache container.
  # -- Example:
  # extraEnv:
  # - name: SOME_VAR
  #   value: 'some value'
  extraEnv: [ ]

  # Component-specific overrides for global settings.
  # If null, global values are used.
  # cache.logLevel -- Log level for the Cache component.
  logLevel: ~
  # cache.logRemote -- Enable/disable remote logging for the Cache component.
  logRemote: ~
  # cache.traceRemote -- Enable/disable remote tracing for the Cache component.
  traceRemote: ~
  # cache.developmentMode -- Enable/disable development mode for the Cache component.
  developmentMode: ~

  # cache.ports -- Port configuration for Cache component.
  ports:
    # cache.ports.probes -- Port configuration for Cache probes.
    probes:
      # cache.ports.probes.name -- Name of the probes port.
      name: probes
      # cache.ports.probes.port -- Port number for health and readiness probes.
      port: 8081

  # cache.rbac -- RBAC configuration for the Cache component.
  rbac:
    # cache.rbac.create -- If true, creates RBAC resources (ClusterRoles, ClusterRoleBindings) for the Cache component.
    create: true

  # cache.serviceAccount -- ServiceAccount configuration for the Cache component.
  serviceAccount:
    # cache.serviceAccount.create -- If true, creates a ServiceAccount for the Cache component.
    create: true
    # cache.serviceAccount.automount -- If true, automatically mounts the service account token in the pod.
    automount: true
    # cache.serviceAccount.annotations -- Annotations to add to the ServiceAccount.
    # Example: {"eks.amazonaws.com/role-arn": "arn:aws:iam::123456789012:role/YourKompassComputeCacheRole"}
    annotations: {}
    # cache.serviceAccount.name -- The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template.
    # If create is false, this specifies an existing ServiceAccount to use.
    name: ""

  # cache.podAnnotations -- Annotations to add to the Cache Pods.
  # See: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"

  # cache.podLabels -- Labels to add to the Cache Pods.
  # See: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  podLabels: {}

  # cache.podSecurityContext -- Security context for the Cache Pods.
  # See: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

  # cache.securityContext -- Security context for the Cache container.
  # See: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true

  # cache.resources -- Resource requests and limits for the Cache container.
  # See: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi

  # cache.startupProbe -- Startup probe configuration for the Cache container.
  # See: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  startupProbe:
    httpGet:
      path: /healthz # Endpoint for the startup probe.
      port: probes  # Port name defined in 'ports'.
    failureThreshold: 50 # Number of consecutive failures for the probe to be considered failed.
    periodSeconds: 10    # How often (in seconds) to perform the probe.
    timeoutSeconds: 5    # Number of seconds after which the probe times out.

  # cache.livenessProbe -- Liveness probe configuration for the Cache container.
  # See: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  livenessProbe:
    httpGet:
      path: /healthz # Endpoint for the liveness probe.
      port: probes  # Port name defined in 'ports'.
    initialDelaySeconds: 15 # Number of seconds after the container has started before liveness probes are initiated.
    periodSeconds: 20       # How often (in seconds) to perform the probe.
    timeoutSeconds: 5       # Number of seconds after which the probe times out.

  # cache.readinessProbe -- Readiness probe configuration for the Cache container.
  # See: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  readinessProbe:
    httpGet:
      path: /readyz # Endpoint for the readiness probe.
      port: probes # Port name defined in 'ports'.
    initialDelaySeconds: 5 # Number of seconds after the container has started before readiness probes are initiated.
    periodSeconds: 10      # How often (in seconds) to perform the probe.
    timeoutSeconds: 5      # Number of seconds after which the probe times out.

  # cache.extraVolumes -- Additional volumes to mount in the Cache Pods.
  # See: https://kubernetes.io/docs/concepts/storage/volumes/
  extraVolumes: []
  # Example:
  # - name: foo
  #   secret:
  #     secretName: mysecret
  #     optional: false

  # cache.extraVolumeMounts -- Additional volume mounts for the Cache containers.
  # See: https://kubernetes.io/docs/concepts/storage/volumes/
  extraVolumeMounts: []
  # Example:
  # - name: foo
  #   mountPath: "/etc/foo"
  #   readOnly: true

  # cache.nodeSelector -- Node selector for scheduling Cache Pods.
  # See: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector
  nodeSelector: {}

  # cache.tolerations -- Tolerations for scheduling Cache Pods.
  # See: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
  tolerations: []

  # cache.affinity -- Affinity rules for scheduling Cache Pods. Overrides default affinity if set.
  # See: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}
  # cache.useDefaultAffinity -- If true, applies default affinity rules. Ignored if 'affinity' is set.
  useDefaultAffinity: true

  # cache.podDisruptionBudget -- PodDisruptionBudget configuration for the Cache deployment.
  # See: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  podDisruptionBudget:
    # cache.podDisruptionBudget.enabled -- If true, creates a PodDisruptionBudget for the Cache deployment.
    # This prevents downtime during voluntary disruptions (e.g., node upgrades).
    enabled: true

    # cache.podDisruptionBudget.minAvailable -- Minimum number/percentage of pods that must remain available during a voluntary disruption.
    # Cannot be used if 'maxUnavailable' is set. Example: 1 or "25%".
    # minAvailable: 1

    # cache.podDisruptionBudget.maxUnavailable -- Maximum number/percentage of pods that can be unavailable during a voluntary disruption.
    # Cannot be used if 'minAvailable' is set. Example: 1 or "25%".
    # If not set and PDB is enabled, defaults to 1.
    # maxUnavailable: 1

# hiberscaler -- Hiberscaler component configuration
hiberscaler:
  # hiberscaler.enabled -- If true, deploys the Hiberscaler component.
  enabled: true

  # hiberscaler.replicaCount -- Number of replicas for the Hiberscaler Deployment.
  replicaCount: 3

  # hiberscaler.image -- Image configuration for the Hiberscaler component.
  image:
    # hiberscaler.image.repository -- Image repository for the Hiberscaler component.
    repository: 672188301118.dkr.ecr.eu-west-1.amazonaws.com/zesty-k8s/kompass-compute/hiberscaler-controller
    # hiberscaler.image.pullPolicy -- Image pull policy.
    pullPolicy: Always
    # hiberscaler.image.tag -- Specific image tag for the Hiberscaler component.
    tag: ""

  # hiberscaler.extraArgs -- Extra command-line arguments to pass to the Hiberscaler container.
  extraArgs: [ ]
  # hiberscaler.extraEnv -- Extra environment variables to set in the Hiberscaler container.
  extraEnv: [ ]

  # hiberscaler.logLevel -- Log level for the Hiberscaler component.
  logLevel: ~
  # hiberscaler.logRemote -- Enable/disable remote logging for the Hiberscaler component.
  logRemote: ~
  # hiberscaler.traceRemote -- Enable/disable remote tracing for the Hiberscaler component.
  traceRemote: ~
  # hiberscaler.developmentMode -- Enable/disable development mode for the Hiberscaler component.
  developmentMode: ~

  # hiberscaler.ports -- Port configuration for the Hiberscaler component.
  ports:
    # hiberscaler.ports.metrics -- Port for metrics exposition (e.g., Prometheus).
    metrics:
      # hiberscaler.ports.metrics.name -- Name of the metrics port.
      name: metrics
      # hiberscaler.ports.metrics.port -- Port number for metrics exposition.
      port: 8080
    # hiberscaler.ports.probes -- Port for health and readiness probes.
    probes:
      # hiberscaler.ports.probes.name -- Name of the probes port.
      name: probes
      # hiberscaler.ports.probes.port -- Port number for health and readiness probes.
      port: 8081
    # hiberscaler.ports.nodeServer -- Port for the Node server.
    nodeServer:
      # hiberscaler.ports.nodeServer.name -- Name of the node server port.
      name: node-server
      # hiberscaler.ports.nodeServer.port -- Port number for the Node server.
      port: 8082
    # hiberscaler.ports.webServer -- Port for the webhook server.
    webServer:
      # hiberscaler.ports.webServer.name -- Name of the webhook server port.
      name: webhook-server
      # hiberscaler.ports.webServer.port -- Port number for the webhook server.
      port: 9443 # Internal port for the webhook server.
      # hiberscaler.ports.webServer.serviceType -- Service type for the webhook.
      serviceType: ClusterIP # Service type for the webhook.
      # hiberscaler.ports.webServer.servicePort -- Port exposed by the webhook service.
      servicePort: 443       # Port exposed by the webhook service.

  # hiberscaler.rbac -- RBAC configuration for the Hiberscaler component.
  rbac:
    # hiberscaler.rbac.create -- If true, creates RBAC resources for the Hiberscaler component.
    create: true

  # hiberscaler.serviceAccount -- ServiceAccount configuration for the Hiberscaler component.
  serviceAccount:
    # hiberscaler.serviceAccount.create -- If true, creates a ServiceAccount for the Hiberscaler component.
    create: true
    # hiberscaler.serviceAccount.automount -- If true, automatically mounts the service account token in the pod.
    automount: true
    # hiberscaler.serviceAccount.annotations -- Annotations to add to the ServiceAccount.
    # Example: {"eks.amazonaws.com/role-arn": "arn:aws:iam::123456789012:role/YourKompassComputeHiberscalerRole"}
    annotations: {}
    # hiberscaler.serviceAccount.name -- The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template.
    # If create is false, this specifies an existing ServiceAccount to use.
    name: ""

  # hiberscaler.podAnnotations -- Annotations to add to the Hiberscaler Pods.
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
  # hiberscaler.podLabels -- Labels to add to the Hiberscaler Pods.
  podLabels: {}

  # hiberscaler.podSecurityContext -- Security context for the Hiberscaler Pods.
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

  # hiberscaler.securityContext -- Security context for the Hiberscaler containers.
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true

  # hiberscaler.resources -- Resource requests and limits for the Hiberscaler Pods.
  resources:
    limits:
      cpu: 2000m
      memory: 4096Mi
    requests:
      cpu: 2000m
      memory: 4096Mi

  # hiberscaler.startupProbe -- Startup probe configuration for the Hiberscaler container.
  startupProbe:
    httpGet:
      path: /healthz
      port: probes
    failureThreshold: 50
    periodSeconds: 10
    timeoutSeconds: 5

  # hiberscaler.livenessProbe -- Liveness probe configuration for the Hiberscaler container.
  livenessProbe:
    httpGet:
      path: /healthz
      port: probes
    initialDelaySeconds: 15
    periodSeconds: 20
    timeoutSeconds: 5

  # hiberscaler.readinessProbe -- Readiness probe configuration for the Hiberscaler container.
  readinessProbe:
    httpGet:
      path: /readyz
      port: probes
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5

  # hiberscaler.extraVolumes -- Extra volumes to add to the Hiberscaler container.
  extraVolumes: []
  # hiberscaler.extraVolumeMounts -- Extra volume mounts to add to the Hiberscaler container.
  extraVolumeMounts: []
  # hiberscaler.nodeSelector -- Node selector for scheduling Hiberscaler Pods.
  nodeSelector: {}
  # hiberscaler.tolerations -- Tolerations for scheduling Hiberscaler Pods.
  tolerations: []
  # hiberscaler.affinity -- Affinity rules for scheduling Hiberscaler Pods. Overrides default affinity if set.
  affinity: {}
  # hiberscaler.useDefaultAffinity -- If true, applies default affinity (e.g., anti-affinity with other Hiberscaler pods on the same node if applicable).
  useDefaultAffinity: true

  # hiberscaler.podDisruptionBudget -- PodDisruptionBudget configuration for the Hiberscaler deployment.
  podDisruptionBudget:
    # hiberscaler.podDisruptionBudget.enabled -- If true, creates a PodDisruptionBudget for the Hiberscaler deployment.
    enabled: false
    # hiberscaler.podDisruptionBudget.minAvailable -- Minimum number/percentage of pods that must remain available during a voluntary disruption.
    # minAvailable: 1
    # hiberscaler.podDisruptionBudget.maxUnavailable -- Maximum number/percentage of pods that can be unavailable during a voluntary disruption.
    # maxUnavailable: 1

# imageSizeCalculator -- ImageSizeCalculator component configuration
# This component is responsible for calculating the size of container images.
# It typically runs as a Job or a similar workload.
imageSizeCalculator:
  # imageSizeCalculator.enabled -- If true, deploys resources related to the ImageSizeCalculator.
  enabled: true

  # imageSizeCalculator.image -- Image configuration for the ImageSizeCalculator.
  image:
    # imageSizeCalculator.image.repository -- Image repository for the ImageSizeCalculator.
    repository: 672188301118.dkr.ecr.eu-west-1.amazonaws.com/zesty-k8s/kompass-compute/image-size-calculator
    # imageSizeCalculator.image.tag -- Specific image tag for the ImageSizeCalculator. If empty, uses the Chart's appVersion.
    tag: ""

  # imageSizeCalculator.extraEnv -- Extra environment variables to set in the ImageSizeCalculator container.
  # Example: extraEnv:
  #   - name: SOME_VAR
  #     value: 'some value'
  extraEnv: [ ]

  # imageSizeCalculator.rbac -- RBAC configuration for the ImageSizeCalculator.
  rbac:
    # imageSizeCalculator.rbac.create -- If true, creates RBAC resources (e.g., Role, RoleBinding) for the ImageSizeCalculator.
    create: true

  # imageSizeCalculator.serviceAccount -- ServiceAccount configuration for the ImageSizeCalculator.
  serviceAccount:
    # imageSizeCalculator.serviceAccount.create -- If true, a ServiceAccount is created for the ImageSizeCalculator.
    create: true
    # imageSizeCalculator.serviceAccount.automount -- If true, automatically mounts the service account token into pods.
    automount: true
    # imageSizeCalculator.serviceAccount.annotations -- Annotations to add to the ServiceAccount.
    # Example: annotations:
    #   eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/YourKompassComputeImageSizeCalculatorRole
    annotations: {}
    # imageSizeCalculator.serviceAccount.name -- Name of the ServiceAccount for the ImageSizeCalculator. If empty, uses the generated name.
    name: ""
  # Note: Other common deployment parameters (replicaCount, probes, etc.) might not be applicable
  # if this component runs as a Job. Refer to its specific templates.

# otel -- OTEL (OpenTelemetry) Collector configuration
otel:
  # otel.enabled -- If true, deploys the OTEL Collector component.
  enabled: true

  # otel.replicaCount -- Number of replicas for the OTEL Collector Deployment.
  replicaCount: 1

  # otel.image -- Image configuration for the OTEL Collector.
  image:
    # otel.image.repository -- Image repository for the OTEL Collector.
    repository: 672188301118.dkr.ecr.eu-west-1.amazonaws.com/zesty-k8s/kompass-compute/otel
    # otel.image.pullPolicy -- Image pull policy.
    pullPolicy: Always
    # otel.image.tag -- Specific image tag for the OTEL Collector.
    tag: ""

  # otel.extraArgs -- Extra command-line arguments to pass to the OTEL Collector container.
  extraArgs: [ ]
  # otel.extraEnv -- Extra environment variables to set in the OTEL Collector container.
  extraEnv: [ ]

  # otel.gomemlimit -- Go memory limit for the OTEL collector. Example: "400MiB".
  gomemlimit: "400MiB"
  # otel.monitorRemote -- Component-specific override for global monitorRemote.
  monitorRemote: ~
  # otel.developmentMode -- Component-specific override for global developmentMode.
  developmentMode: ~

  # otel.ports -- Port configuration for the OTEL Collector.
  ports:
    # otel.ports.otlp -- Port for OTLP gRPC receiver.
    otlp:
      # otel.ports.otlp.name -- Name of the port for OTLP gRPC receiver.
      name: otlp
      # otel.ports.otlp.port -- Port number for OTLP gRPC receiver.
      port: 4317
    # otel.ports.otlpHttp -- Port for OTLP HTTP receiver.
    otlpHttp:
      # otel.ports.otlpHttp.name -- Name of the port for OTLP HTTP receiver.
      name: otlp-http
      # otel.ports.otlpHttp.port -- Port number for OTLP HTTP receiver.
      port: 4318
    # otel.ports.probes -- Port for OTEL Collector's own health and readiness probes.
    probes:
      # otel.ports.probes.name -- Name of the port for OTEL Collector's own health and readiness probes.
      name: probes
      # otel.ports.probes.port -- Port number for OTEL Collector's own health and readiness probes.
      port: 13133

  # otel.rbac -- RBAC configuration for the OTEL Collector.
  rbac:
    # otel.rbac.create -- If true, creates RBAC resources for the OTEL Collector.
    create: true

  # otel.serviceAccount -- ServiceAccount configuration for the OTEL Collector.
  serviceAccount:
    # otel.serviceAccount.create -- If true, creates a ServiceAccount for the OTEL Collector.
    create: true
    # otel.serviceAccount.automount -- If true, automatically mounts the service account token in the pod.
    automount: true
    # otel.serviceAccount.annotations -- Annotations to add to the ServiceAccount.
    annotations: {}
    # otel.serviceAccount.name -- The name of the ServiceAccount to use.
    name: ""

  # otel.podAnnotations -- Annotations to add to the OTEL Collector Pods.
  podAnnotations: {}
  # otel.podLabels -- Labels to add to the OTEL Collector Pods.
  podLabels: {}

  # otel.podSecurityContext -- Security context for the OTEL Collector Pods.
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

  # otel.securityContext -- Security context for the OTEL Collector containers.
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true

  # otel.resources -- Resource requests and limits for the OTEL Collector Pods.
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 256Mi

  # otel.startupProbe -- Startup probe configuration for the OTEL Collector container.
  startupProbe:
    failureThreshold: 50
    httpGet:
      path: / # Health check path for OTEL collector.
      port: probes
  # otel.livenessProbe -- Liveness probe configuration for the OTEL Collector container.
  livenessProbe:
    httpGet:
      path: / # Health check path for OTEL collector.
      port: probes
    timeoutSeconds: 10
  # otel.readinessProbe -- Readiness probe configuration for the OTEL Collector container.
  readinessProbe:
    httpGet:
      path: / # Health check path for OTEL collector.
      port: probes
    timeoutSeconds: 8

  # otel.extraVolumes -- Additional volumes to mount in the OTEL Collector Pods.
  extraVolumes: []
  # otel.extraVolumeMounts -- Additional volume mounts for the OTEL Collector containers.
  extraVolumeMounts: []
  # otel.nodeSelector -- Node selector for scheduling OTEL Collector Pods.
  nodeSelector: {}
  # otel.tolerations -- Tolerations for scheduling OTEL Collector Pods.
  tolerations: []
  # otel.affinity -- Affinity rules for scheduling OTEL Collector Pods. Overrides default affinity if set.
  affinity: {}
  # otel.useDefaultAffinity -- If true, applies default affinity rules. Ignored if 'affinity' is set.
  useDefaultAffinity: true

  # otel.podDisruptionBudget -- PodDisruptionBudget configuration for the OTEL Collector deployment.
  podDisruptionBudget:
    # otel.podDisruptionBudget.enabled -- If true, creates a PodDisruptionBudget for the OTEL Collector deployment.
    enabled: false
    # otel.podDisruptionBudget.minAvailable -- Minimum number/percentage of pods that must remain available during a voluntary disruption.
    # minAvailable: 1
    # otel.podDisruptionBudget.maxUnavailable -- Maximum number/percentage of pods that can be unavailable during a voluntary disruption.
    # maxUnavailable: 1

# snapshooter -- Snapshooter component configuration
snapshooter:
  # snapshooter.enabled -- If true, deploys the Snapshooter component
  enabled: true

  # snapshooter.replicaCount -- Number of replicas for the Snapshooter Deployment
  replicaCount: 1

  # snapshooter.image -- Image configuration for the Snapshooter component
  image:
    # snapshooter.image.repository -- Image repository for the Snapshooter component
    repository: 672188301118.dkr.ecr.eu-west-1.amazonaws.com/zesty-k8s/kompass-compute/snapshooter
    # snapshooter.image.pullPolicy -- Image pull policy for the Snapshooter component
    pullPolicy: Always
    # snapshooter.image.tag -- Specific image tag for the Snapshooter component
    tag: ""

  # snapshooter.extraArgs -- Additional command line arguments for the Snapshooter container
  extraArgs: [ ]
  # snapshooter.extraEnv -- Additional environment variables for the Snapshooter container
  extraEnv: [ ]

  # snapshooter.logLevel -- Component-specific override for global log level
  logLevel: ~
  # snapshooter.logRemote -- Component-specific override for global remote logging configuration
  logRemote: ~
  # snapshooter.traceRemote -- Component-specific override for global remote tracing configuration
  traceRemote: ~
  # snapshooter.developmentMode -- Component-specific override for global development mode
  developmentMode: ~

  # snapshooter.ports -- Port configuration for the Snapshooter component
  ports:
    # snapshooter.ports.probes -- Port for Snapshooter health and readiness probes
    probes:
      # snapshooter.ports.probes.name -- Name of the port for health and readiness probes
      name: probes
      # snapshooter.ports.probes.port -- Port number for health and readiness probes
      port: 8081

  # snapshooter.rbac -- RBAC configuration for the Snapshooter component
  rbac:
    # snapshooter.rbac.create -- If true, creates RBAC resources for the Snapshooter component
    create: true

  # snapshooter.serviceAccount -- ServiceAccount configuration for the Snapshooter component
  serviceAccount:
    # snapshooter.serviceAccount.create -- If true, creates a ServiceAccount for the Snapshooter component
    create: true
    # snapshooter.serviceAccount.automount -- If true, automounts the Kubernetes API credentials for the ServiceAccount
    automount: true
    # snapshooter.serviceAccount.annotations -- Annotations to add to the ServiceAccount
    annotations: {}
    # snapshooter.serviceAccount.name -- Name of the ServiceAccount to use
    name: ""

  # snapshooter.podAnnotations -- Annotations to add to the Snapshooter pods
  podAnnotations: {}
  # snapshooter.podLabels -- Labels to add to the Snapshooter pods
  podLabels: {}

  # snapshooter.podSecurityContext -- Security context for the Snapshooter pod
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

  # snapshooter.securityContext -- Security context for the Snapshooter container
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true

  # snapshooter.resources -- Resource requests and limits for the Snapshooter container
  resources:
    limits:
      cpu: 300m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi

  # snapshooter.startupProbe -- Startup probe configuration for the Snapshooter container
  startupProbe:
    httpGet:
      path: /healthz
      port: probes
    failureThreshold: 50
    periodSeconds: 10
    timeoutSeconds: 5
  # snapshooter.livenessProbe -- Liveness probe configuration for the Snapshooter container
  livenessProbe:
    httpGet:
      path: /healthz
      port: probes
    initialDelaySeconds: 15
    periodSeconds: 20
    timeoutSeconds: 5
  # snapshooter.readinessProbe -- Readiness probe configuration for the Snapshooter container
  readinessProbe:
    httpGet:
      path: /readyz
      port: probes
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5

  # snapshooter.extraVolumes -- Additional volumes to mount in the Snapshooter pods
  extraVolumes: []
  # snapshooter.extraVolumeMounts -- Additional volume mounts for the Snapshooter container
  extraVolumeMounts: []
  # snapshooter.nodeSelector -- Node selector for scheduling Snapshooter pods
  nodeSelector: {}
  # snapshooter.tolerations -- Tolerations for scheduling Snapshooter pods
  tolerations: []
  # snapshooter.affinity -- Affinity rules for scheduling Snapshooter pods. Overrides default affinity if set
  affinity: {}
  # snapshooter.useDefaultAffinity -- If true, applies default affinity rules. Ignored if 'affinity' is set
  useDefaultAffinity: true

  # snapshooter.terminationGracePeriodSeconds -- Grace period (in seconds) for the Snapshooter pod to terminate
  terminationGracePeriodSeconds: 60

  # snapshooter.podDisruptionBudget -- PodDisruptionBudget configuration for the Snapshooter deployment
  podDisruptionBudget:
    # snapshooter.podDisruptionBudget.enabled -- If true, creates a PodDisruptionBudget for the Snapshooter deployment
    enabled: false
    # snapshooter.podDisruptionBudget.minAvailable -- Minimum number/percentage of pods that must remain available during a voluntary disruption
    # minAvailable: 1
    # snapshooter.podDisruptionBudget.maxUnavailable -- Maximum number/percentage of pods that can be unavailable during a voluntary disruption
    # maxUnavailable: 1

# telemetryManager -- Telemetry Manager component configuration
telemetryManager:
  # telemetryManager.enabled -- If true, deploys the Telemetry Manager component
  enabled: true

  # telemetryManager.replicaCount -- Number of replicas for the Telemetry Manager Deployment
  replicaCount: 1

  # telemetryManager.image -- Image configuration for the Telemetry Manager component
  image:
    # telemetryManager.image.repository -- Image repository for the Telemetry Manager component
    repository: 672188301118.dkr.ecr.eu-west-1.amazonaws.com/zesty-k8s/kompass-compute/telemetry-manager
    # telemetryManager.image.pullPolicy -- Image pull policy for the Telemetry Manager container
    pullPolicy: Always
    # telemetryManager.image.tag -- Specific image tag for the Telemetry Manager component
    tag: ""

  # telemetryManager.extraArgs -- Additional command line arguments for the Telemetry Manager container
  extraArgs: [ ]
  # telemetryManager.extraEnv -- Additional environment variables for the Telemetry Manager container
  extraEnv: [ ]

  # telemetryManager.logLevel -- Component-specific override for global log level
  logLevel: ~
  # telemetryManager.logRemote -- Component-specific override for global log remote endpoint
  logRemote: ~
  # telemetryManager.traceRemote -- Component-specific override for global trace remote endpoint
  traceRemote: ~
  # telemetryManager.developmentMode -- Component-specific override for global development mode
  developmentMode: ~

  # telemetryManager.ports -- Port configuration for the Telemetry Manager component
  ports:
    # telemetryManager.ports.probes -- Port for Telemetry Manager health and readiness probes
    probes:
      # telemetryManager.ports.probes.name -- Name of the port
      name: probes
      # telemetryManager.ports.probes.port -- Port number for the Telemetry Manager health and readiness probes
      port: 8081
    # telemetryManager.ports.metrics -- Port for metrics exposition
    metrics:
      # telemetryManager.ports.metrics.name -- Name of the port
      name: metrics
      # telemetryManager.ports.metrics.port -- Port number for metrics exposition
      port: 8080

  # telemetryManager.rbac -- RBAC configuration for the Telemetry Manager component
  rbac:
    # telemetryManager.rbac.create -- If true, creates RBAC resources for the Telemetry Manager component
    create: true

  # telemetryManager.serviceAccount -- ServiceAccount configuration for the Telemetry Manager component
  serviceAccount:
    # telemetryManager.serviceAccount.create -- If true, creates a ServiceAccount for the Telemetry Manager component
    create: true
    # telemetryManager.serviceAccount.automount -- If true, automounts the Kubernetes API credentials for the ServiceAccount
    automount: true
    # telemetryManager.serviceAccount.annotations -- Annotations to add to the ServiceAccount
    annotations: {}
    # telemetryManager.serviceAccount.name -- The name of the ServiceAccount to use
    name: ""

  # telemetryManager.podAnnotations -- Annotations to add to the Telemetry Manager Pods
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
  # telemetryManager.podLabels -- Additional labels to add to the Telemetry Manager Pods
  podLabels: {}

  # telemetryManager.podSecurityContext -- Security context for the Telemetry Manager pods
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

  # telemetryManager.securityContext -- Security context for the Telemetry Manager container
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true

  # telemetryManager.resources -- Resource requests and limits for the Telemetry Manager container
  resources:
    limits:
      cpu: 400m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 256Mi

  # telemetryManager.startupProbe -- Startup probe configuration for the Telemetry Manager container
  startupProbe:
    httpGet:
      path: /healthz
      port: probes
    failureThreshold: 50
    periodSeconds: 10
    timeoutSeconds: 5
  # telemetryManager.livenessProbe -- Liveness probe configuration for the Telemetry Manager container
  livenessProbe:
    httpGet:
      path: /healthz
      port: probes
    initialDelaySeconds: 15
    periodSeconds: 20
    timeoutSeconds: 5
  # telemetryManager.readinessProbe -- Readiness probe configuration for the Telemetry Manager container
  readinessProbe:
    httpGet:
      path: /readyz
      port: probes
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5

  # telemetryManager.extraVolumes -- Additional volumes to mount in the Telemetry Manager pods
  extraVolumes: []
  # telemetryManager.extraVolumeMounts -- Additional volume mounts for the Telemetry Manager container
  extraVolumeMounts: []
  # telemetryManager.nodeSelector -- Node selector for scheduling Telemetry Manager pods
  nodeSelector: {}
  # telemetryManager.tolerations -- Tolerations for scheduling Telemetry Manager pods
  tolerations: []
  # telemetryManager.affinity -- Affinity rules for scheduling Telemetry Manager pods. Overrides default affinity if set
  affinity: {}
  # telemetryManager.useDefaultAffinity -- If true, applies default affinity rules. Ignored if 'affinity' is set
  useDefaultAffinity: true

  # telemetryManager.podDisruptionBudget -- PodDisruptionBudget configuration for the Telemetry Manager deployment
  podDisruptionBudget:
    # telemetryManager.podDisruptionBudget.enabled -- If true, creates a PodDisruptionBudget for the Telemetry Manager deployment
    enabled: false
    # telemetryManager.podDisruptionBudget.minAvailable -- Minimum number/percentage of pods that must remain available during a voluntary disruption
    # minAvailable: 1
    # telemetryManager.podDisruptionBudget.maxUnavailable -- Maximum number/percentage of pods that can be unavailable during a voluntary disruption
    # maxUnavailable: 1

# vector -- Vector component configuration (for log aggregation/forwarding)
vector:
  # vector.enabled -- If true, deploys the Vector component (typically as a DaemonSet)
  enabled: true

  # vector.image -- Image configuration for Vector
  image:
    # vector.image.repository -- Image repository for Vector
    repository: 672188301118.dkr.ecr.eu-west-1.amazonaws.com/zesty-k8s/kompass-compute/vector
    # vector.image.pullPolicy -- Image pull policy for Vector container
    pullPolicy: Always
    # vector.image.tag -- Specific image tag for Vector. Note: Vector often has its own versioning
    tag: ""

  # vector.extraArgs -- Additional command line arguments for the Vector container
  extraArgs: [ ]
  # vector.extraEnv -- Additional environment variables for the Vector container
  extraEnv: [ ]

  # vector.logLevel -- Component-specific override for global log level
  logLevel: ~
  # vector.developmentMode -- Component-specific override for global development mode
  developmentMode: ~

  # vector.rbac -- RBAC configuration for the Vector component
  rbac:
    # vector.rbac.create -- If true, creates RBAC resources for Vector
    create: true

  # vector.serviceAccount -- ServiceAccount configuration for the Vector component
  serviceAccount:
    # vector.serviceAccount.create -- If true, creates a ServiceAccount for Vector
    create: true
    # vector.serviceAccount.automount -- If true, automounts the Kubernetes API credentials for the ServiceAccount
    automount: true
    # vector.serviceAccount.annotations -- Annotations to add to the ServiceAccount
    annotations: {}
    # vector.serviceAccount.name -- The name of the ServiceAccount to use
    name: ""

  # vector.podAnnotations -- Annotations to add to the Vector Pods
  podAnnotations: {}
  # vector.podLabels -- Additional labels to add to the Vector Pods
  podLabels: {}

  # vector.podSecurityContext -- Security context for Vector Pods
  podSecurityContext:
    # vector.podSecurityContext.fsGroup -- Group ID for the filesystem used by Vector
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault
    # vector.podSecurityContext.runAsUser -- User ID for Vector processes
    # runAsUser: 0
    # vector.podSecurityContext.runAsGroup -- Group ID for Vector processes
    # runAsGroup: 0
    # vector.podSecurityContext.runAsNonRoot -- If true, Vector must run as a non-root user
    # runAsNonRoot: false

  # vector.securityContext -- Security context for Vector containers
  securityContext:
    # vector.securityContext.allowPrivilegeEscalation -- If true, allows the Vector process to gain more privileges than its parent process
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    # vector.securityContext.readOnlyRootFilesystem -- If true, mounts the container's root filesystem as read-only
    readOnlyRootFilesystem: true

  # vector.resources -- Resource requests and limits for Vector containers
  resources:
    limits:
      cpu: 300m
      memory: 600Mi
    requests:
      cpu: 10m
      memory: 50Mi

  # vector.extraVolumes -- Additional volumes to mount in the Vector pods
  extraVolumes: []
  # vector.extraVolumeMounts -- Additional volume mounts for the Vector container
  extraVolumeMounts: []

  # vector.normal -- Configuration for Vector running on normal Kubernetes nodes
  normal:
    # vector.normal.nodeSelector -- Node selector for Vector pods on normal nodes
    nodeSelector: { }
    # vector.normal.tolerations -- Tolerations for Vector pods on normal nodes
    tolerations:
      - operator: Exists
    # vector.normal.affinity -- Affinity settings for Vector pods on normal nodes
    affinity: { }
    # vector.normal.useDefaultAffinity -- If true, applies default affinity rules. Ignored if 'affinity' is set
    useDefaultAffinity: true

  # vector.qNode -- Configuration for Vector running on QNode (Qubex specific nodes)
  qNode:
    # vector.qNode.nodeSelector -- Node selector for Vector pods on QNodes
    nodeSelector: {}
    # vector.qNode.tolerations -- Tolerations for Vector pods on QNodes
    tolerations:
      - operator: Exists
    # vector.qNode.affinity -- Affinity settings for Vector pods on QNodes
    affinity: {}
    # vector.qNode.useDefaultAffinity -- If true, applies default affinity rules. Ignored if 'affinity' is set
    useDefaultAffinity: true

# uninstaller -- Uninstaller Job configuration
# This component is typically a Job responsible for cleanup tasks during chart uninstallation.
uninstaller:
  # uninstaller.enabled -- If true, resources for the Uninstaller Job are created
  enabled: true

  # uninstaller.image -- Image configuration for the Uninstaller Job
  image:
    # uninstaller.image.repository -- Image repository for the Uninstaller container
    repository: 672188301118.dkr.ecr.eu-west-1.amazonaws.com/zesty-k8s/kompass-compute/uninstaller
    # uninstaller.image.pullPolicy -- Image pull policy for the Uninstaller container
    pullPolicy: Always
    # uninstaller.image.tag -- Specific image tag for the Uninstaller
    tag: ""

  # uninstaller.extraArgs -- Additional command line arguments for the Uninstaller container
  extraArgs: [ ]
  # uninstaller.extraEnv -- Additional environment variables for the Uninstaller container
  extraEnv: [ ]

  # uninstaller.logLevel -- Component-specific override for global log level
  logLevel: ~
  # uninstaller.logRemote -- Component-specific override for global remote logging
  logRemote: ~
  # uninstaller.traceRemote -- Component-specific override for global remote tracing
  traceRemote: ~
  # uninstaller.developmentMode -- Component-specific override for global development mode
  developmentMode: ~

  # uninstaller.rbac -- RBAC configuration for the Uninstaller component
  rbac:
    # uninstaller.rbac.create -- If true, creates RBAC resources for the Uninstaller Job
    create: true

  # uninstaller.serviceAccount -- ServiceAccount configuration for the Uninstaller component
  serviceAccount:
    # uninstaller.serviceAccount.create -- If true, creates a ServiceAccount for the Uninstaller
    create: true
    # uninstaller.serviceAccount.automount -- If true, automounts the Kubernetes API credentials for the ServiceAccount
    automount: true
    # uninstaller.serviceAccount.annotations -- Annotations to add to the ServiceAccount
    annotations: {}
    # uninstaller.serviceAccount.name -- The name of the ServiceAccount to use
    name: ""

  # uninstaller.podAnnotations -- Annotations to add to the Uninstaller Pod
  podAnnotations: {}
  # uninstaller.podLabels -- Additional labels to add to the Uninstaller Pod
  podLabels: {}

  # uninstaller.podSecurityContext -- Security context for Uninstaller Pod
  podSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    fsGroup: 1000
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

  # uninstaller.securityContext -- Security context for Uninstaller container
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true

  # uninstaller.resources -- Resource requests and limits for the Uninstaller container
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi

  # uninstaller.extraVolumes -- Additional volumes to mount in the Uninstaller Pod
  extraVolumes: []
  # uninstaller.extraVolumeMounts -- Additional volume mounts for the Uninstaller container
  extraVolumeMounts: []
  # uninstaller.nodeSelector -- Node selector for scheduling Uninstaller Pod
  nodeSelector: {}
  # uninstaller.tolerations -- Tolerations for scheduling Uninstaller Pod
  tolerations: []

  # uninstaller.affinity -- Affinity rules for scheduling Uninstaller Pod
  affinity: {}

# qnode -- QNode specific configuration
qnode:
  # qnode.enabled -- If true, enables QNode specific features or deployments.
  # The exact impact depends on how this is used in templates.
  enabled: true

# qubexConfig -- QubexConfig
qubexConfig:
  # qubexConfig.cloudProvider -- The cloud provider
  cloudProvider: eks
  # qubexConfig.nodeAgentHTTPAddressPrefix -- Path to NodeAgent HTTP address prefix
  # The S3 bucket from which the QNode will download the Qubex assets
  # Override the node agent HTTP address prefix if you want to use a custom one.
  # Default is https://kompass-compute.s3.eu-west-1.amazonaws.com/<HIBERSCALER_TAG>
  # nodeAgentHTTPAddressPrefix: ...

  # qubexConfig.architectures -- List of supported architectures
  # architectures: [...]
  # qubexConfig.infraConfig -- Infrastructure configuration
  infraConfig:
    # qubexConfig.infraConfig.aws -- AWS specific configuration
    aws: {}
      # qubexConfig.infraConfig.aws.zones -- The zones to take into account
      # zones: [...]

      # qubexConfig.infraConfig.aws.additionalTags -- Additional AWS tags added to resources created by Qubex Controllers
      # additionalTags: [...]

      # qubexConfig.infraConfig.aws.spotFailuresQueueUrl -- The SQS queue for spot failures events
      # spotFailuresQueueUrl: ...

      # qubexConfig.infraConfig.aws.s3VpcEndpointID -- The ID of the S3 VPC endpoint
      # s3VpcEndpointID: ...

      # qubexConfig.infraConfig.aws.s3VpcEndpointIPAddresses -- The IP addresses for S3 VPC endpoint per region
      # s3VpcEndpointIPAddresses: [...]

      # qubexConfig.infraConfig.aws.resumeVMStartInstanceBucketSize -- Bucket size used to cover for AWS API rate limit token bucket implementation
      # resumeVMStartInstanceBucketSize: ...

      # qubexConfig.infraConfig.aws.resumeVMStartInstanceFillRate -- Bucket fill rate used to cover for AWS API rate limit token bucket implementation
      # resumeVMStartInstanceFillRate: ...

      # qubexConfig.infraConfig.aws.autodiscovery -- Whether or not to enable autodiscovery, used for preventing race conditions during uninstallation
      # autodiscovery: true

      # qubexConfig.infraConfig.aws.containerRuntime -- The type of container runtime to use
      # containerRuntime: ...

      # qubexConfig.infraConfig.aws.enableNonTrunkingInstances -- Enable non-trunking instances
      # enableNonTrunkingInstances: true

      # qubexConfig.infraConfig.aws.enableM7FlexInstances -- Enable m7i-flex instances
      # enableM7FlexInstances: true

      # qubexConfig.infraConfig.aws.baseDiskSize -- The disk size used by Qubex VMs will be (BaseDiskSize + <instance memory size>)
      # baseDiskSize: ...

  # qubexConfig.defaultWorkloadProtectionThreshold -- The default workload protection threshold
  # defaultWorkloadProtectionThreshold: ...

  # qubexConfig.resumingNodesRatio -- The ratio between the number of VM resumed and the number of the VMs that will be allowed to join the cluster
  # resumingNodesRatio: ...

  # qubexConfig.instanceTypesCount -- How many instance types should be selected for each QScaler
  # instanceTypesCount: ...

  # qubexConfig.instanceTypeMaxCPU -- Maximum CPU for instance type
  # instanceTypeMaxCPU: ...

  # qubexConfig.spotOceanConfig -- Spot.io Ocean integration configuration
  spotOceanConfig: {}
    # qubexConfig.spotOceanConfig.enable -- Enable turns on Spot.io Ocean integration
    # enable: ...

    # qubexConfig.spotOceanConfig.spotOceanID -- ID of the spot ocean cluster
    # spotOceanID: ...

    # qubexConfig.spotOceanConfig.spotOceanSecretName -- Name of the secret containing the spot.io credentials
    # spotOceanSecretName: ...

    # qubexConfig.spotOceanConfig.spotOceanSecretNamespace -- Namespace of the secret containing the spot.io credentials
    # spotOceanSecretNamespace: ...

    # qubexConfig.spotOceanConfig.spotOceanSecretTokenKey -- Key in the secret containing the spot.io token
    # spotOceanSecretTokenKey: ...

    # qubexConfig.spotOceanConfig.spotOceanSecretAccountKey -- Key in the secret containing the spot.io account
    # spotOceanSecretAccountKey: ...

  # qubexConfig.drainingConfig -- Configuration for node draining
  drainingConfig: {}
    # qubexConfig.drainingConfig.scaleInProtectionDuration -- Scale in protection for Qubex VMs. Before this time elapses, machines will not be scheduled for removal
    # scaleInProtectionDuration: ...

    # qubexConfig.drainingConfig.drainGracePeriod -- The grace period of self managed drain before force termination
    # drainGracePeriod: ...

    # qubexConfig.drainingConfig.replacementPodRetryInterval -- The time after Qubex will create another replacement pod for the same workload
    # replacementPodRetryInterval: ...

  # qubexConfig.disturbanceConfig -- Configuration for disturbance handling
  disturbanceConfig: {}
    # qubexConfig.disturbanceConfig.cooldownPeriod -- Time to wait for disturbance to be cold before committing a disturbance event
    # cooldownPeriod: ...

  # qubexConfig.cacheConfig -- Configuration for container image caching
  cacheConfig:
    # qubexConfig.cacheConfig.diskSize -- The disk size for container cache in GB
    # diskSize: ...

    # qubexConfig.cacheConfig.diskFillAmount -- The amount of disk which can be filled by cached images
    # diskFillAmount: ...

    # qubexConfig.cacheConfig.additionalImages -- List of custom images which have to be cached
    # additionalImages: ...

    # qubexConfig.cacheConfig.revisionMinCreationInterval -- Default interval between QCache revisions creation
    # revisionMinCreationInterval: ...

    # qubexConfig.cacheConfig.workloadsPerRevisionCreation -- Number of workloads per RevisionCreation
    # workloadsPerRevisionCreation: ...

    # qubexConfig.cacheConfig.concurrentImagePullPerRevisionCreation -- Number of concurrent image pulls per revision creation
    # concurrentImagePullPerRevisionCreation: ...

    # qubexConfig.cacheConfig.concurrentLayerPullPerRevisionCreation -- Number of concurrent layers pulls per revision creation
    # concurrentLayerPullPerRevisionCreation: ...

    # qubexConfig.cacheConfig.revisionCreationTimeout -- Timeout for QCacheRevisionCreation to finish
    # revisionCreationTimeout: ...

    # qubexConfig.cacheConfig.workloadExpirationTime -- Old Workload expiration time
    # workloadExpirationTime: ...

    # qubexConfig.cacheConfig.workloadsExpirationCount -- Old Workload expiration count
    # workloadsExpirationCount: ...

    # qubexConfig.cacheConfig.shardsToMergeCount -- Number of shards to merge
    # shardsToMergeCount: ...

    # qubexConfig.cacheConfig.acceptableLagResumeRatio -- Acceptable ratio of missing images in cache to qualify for resumption
    # acceptableLagResumeRatio: ...

    # qubexConfig.cacheConfig.imageSizeCalculatorConfig -- Configuration for image size calculator
    imageSizeCalculatorConfig:
      # qubexConfig.cacheConfig.imageSizeCalculatorConfig.image -- Override the image size calculator image if you want to use a custom one
      # image: ...

      # qubexConfig.cacheConfig.imageSizeCalculatorConfig.jobNamePrefix -- Override the image size calculator job name if you want to use a custom one
      # jobNamePrefix: ...

      # qubexConfig.cacheConfig.imageSizeCalculatorConfig.serviceAccountName -- Override the image size calculator service account name if you want to use a custom one
      # serviceAccountName: ...

      # qubexConfig.cacheConfig.imageSizeCalculatorConfig.pullSecrets -- Override the image size calculator pull secrets if you want to use a custom one
      # pullSecrets: ...

  # qubexConfig.snapshooterInterval -- Snapshooter interval
  # snapshooterInterval: ...

  # qubexConfig.enableExperimentalFeatures -- Enable experimental features
  # enableExperimentalFeatures: ...

  # qubexConfig.zestyConfig -- Zesty configuration
  zestyConfig: {}
    # qubexConfig.zestyConfig.uploadInterval -- Upload interval
    # uploadInterval: ...

# cachePullMappings -- Configuration for mapping image registries to proxies/caches
cachePullMappings: {}
# Example:
#  dockerhub:
#    - proxyAddress: ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/zesty-dockerhub
#  ecr:
#    - proxyAddress: ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/zesty-ecr
#  ghcr:
#    - proxyAddress: ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/zesty-ghcr
#  k8s:
#    - proxyAddress: ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/zesty-k8s
#  quay:
#    - proxyAddress: ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/zesty-quay
#  custom:
#    - originalHost: custom.registry.com
#      additionalAliases:
#        - custom-1.registry.com
#      proxyAddress: ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/CUSTOM
#      pullSecret: ""
#      
